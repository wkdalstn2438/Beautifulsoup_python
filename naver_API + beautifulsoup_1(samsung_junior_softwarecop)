import requests
import streamlit as st
from bs4 import BeautifulSoup
import webbrowser
import os
import sys
import urllib.request
import json

url = "https://www.juniorsoftwarecup.com/Awards"
respones = requests.get(url)


if respones.status_code == 200:
    print("Success")
    source = respones.text
    soup = BeautifulSoup(source, 'html.parser')

    ex = soup.findAll("h1", {"class":"tit"})

    top_list = soup.findAll("div", {"class":"tit"})

    p = soup.find_all('p')
    top_list = soup.find_all(attrs={'class':'tit'})

    index = -1
    st.title("삼성주니어 sw대회 수상작")
    a = ''
    for i in top_list:
        if index == 1:
            a = "대상"
        elif index > 1 and index < 5:
            a = "최우수상"
        else:
            a = '우수상'
        if index > 0:
            print(index, i.text.strip())

            st.subheader("{}: {}".format(a, i.text.strip()))
            url = ("https://www.juniorsoftwarecup.com/Awards/Detail/{}?pageidx=1&dtlGbn=2021".format(371 - index+1))
            client_id = "Wr5YiyqRqVjReEZgKaw6"  # 개발자센터에서 발급받은 Client ID 값
            client_secret = "mdiFkrtffs"  # 개발자센터에서 발급받은 Client Secret 값
            encText = urllib.parse.quote(url)
            data = "url=" + encText
            url1 = "https://openapi.naver.com/v1/util/shorturl"
            request = urllib.request.Request(url1)
            request.add_header("X-Naver-Client-Id", client_id)
            request.add_header("X-Naver-Client-Secret", client_secret)
            response = urllib.request.urlopen(request, data=data.encode("utf-8"))
            rescode = response.getcode()
            if (rescode == 200):
                response_body = response.read()
                body = response_body.decode('utf-8')
                data = json.loads(body)
                print(response_body.decode('utf-8'))
                print(data['result']['url'])
            else:
                print("Error Code:" + rescode)
            if st.button("{}".format(i.text.strip())):
                webbrowser.open_new_tab(url)
        index += 1
        if index == 11:
            break
    soup.find_all(['h1', 'p'])
